Notebook: EfficientNetB0_224_32.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB0_224_64.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB0_224_128_512_256_128.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB4_224_32_64_02.ipynb
Error: An error occurred while executing the following cell:
------------------
# %%
# Import necessary libraries at the top
import os
import glob
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from tensorflow.keras.applications import EfficientNetB4
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from datetime import datetime

# --- Configuration & Constants ---
MODEL_NAME = 'EfficientNetB4_Binary'

BASE_DATASET_PATH = './k_CBIS-DDSM/'
CALC_METADATA_CSV_PATH = os.path.join(BASE_DATASET_PATH, 'calc_case(with_jpg_img).csv')
MASS_METADATA_CSV_PATH = os.path.join(BASE_DATASET_PATH, 'mass_case(with_jpg_img).csv')

IMAGE_ROOT_DIR = BASE_DATASET_PATH
ACTUAL_IMAGE_FILES_BASE_DIR = os.path.join(IMAGE_ROOT_DIR, 'jpg_img')

# Column in CSV that conceptually should point to ROIs, even if paths are flawed
CONCEPTUAL_ROI_COLUMN_NAME = 'jpg_ROI_img_path'
PATHOLOGY_COLUMN_NAME = 'pathology'
CASE_TYPE_COLUMN_NAME = 'case_type'

# Model & Training Parameters
IMG_WIDTH, IMG_HEIGHT = 224, 224
BATCH_SIZE = 32
EPOCHS = 500
FINE_TUNE_EPOCHS = 100
LEARNING_RATE = 1e-4
RANDOM_STATE = 42

PATIENCE_EARLY_STOPPING = 25
PATIENCE_REDUCE_LR = 10

PATIENCE_EARLY_STOPPING_FT = 20
PATIENCE_REDUCE_LR_FT = 10

OUTPUT_DIR = os.path.join('./', f"run_{MODEL_NAME}_{IMG_WIDTH}_{BATCH_SIZE}_64_02_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f"All output will be saved to: {os.path.abspath(OUTPUT_DIR)}")

# --- End of Configuration & Constants ---

# %%
# --- [The data loading and path finding sections remain the same as your original script] ---
# ... (Assuming this part runs successfully as in your script)
print("--- Initial Path Configuration Debug ---")
print(f"Current working directory (CWD): {os.getcwd()}")
print(f"BASE_DATASET_PATH (relative from CWD as defined): {BASE_DATASET_PATH}")
print(f"CALC_METADATA_CSV_PATH (relative from CWD as defined): {CALC_METADATA_CSV_PATH}") 
print(f"MASS_METADATA_CSV_PATH (relative from CWD as defined): {MASS_METADATA_CSV_PATH}")   # ADDED
print(f"IMAGE_ROOT_DIR (relative from CWD as defined): {IMAGE_ROOT_DIR}")
print(f"ACTUAL_IMAGE_FILES_BASE_DIR (relative from CWD as defined): {ACTUAL_IMAGE_FILES_BASE_DIR}")

# Resolve to absolute paths for clarity and checking
abs_base_dataset_path = os.path.abspath(BASE_DATASET_PATH)
abs_calc_metadata_csv_path = os.path.abspath(CALC_METADATA_CSV_PATH) 
abs_mass_metadata_csv_path = os.path.abspath(MASS_METADATA_CSV_PATH)   # ADDED
abs_image_root_dir = os.path.abspath(IMAGE_ROOT_DIR)
abs_actual_image_files_base_dir = os.path.abspath(ACTUAL_IMAGE_FILES_BASE_DIR)

print(f"\nResolved BASE_DATASET_PATH to absolute: {abs_base_dataset_path}")
print(f"  -> Exists? {os.path.exists(abs_base_dataset_path)} | Is Dir? {os.path.isdir(abs_base_dataset_path)}")

print(f"Resolved CALC_METADATA_CSV_PATH to absolute: {abs_calc_metadata_csv_path}") 
print(f"  -> Exists? {os.path.exists(abs_calc_metadata_csv_path)} | Is File? {os.path.isfile(abs_calc_metadata_csv_path)}")

print(f"Resolved MASS_METADATA_CSV_PATH to absolute: {abs_mass_metadata_csv_path}")   # ADDED
print(f"  -> Exists? {os.path.exists(abs_mass_metadata_csv_path)} | Is File? {os.path.isfile(abs_mass_metadata_csv_path)}")

print(f"Resolved IMAGE_ROOT_DIR to absolute: {abs_image_root_dir}")
print(f"  -> Exists? {os.path.exists(abs_image_root_dir)} | Is Dir? {os.path.isdir(abs_image_root_dir)}")

print(f"Resolved ACTUAL_IMAGE_FILES_BASE_DIR (where series folders should be): {abs_actual_image_files_base_dir}")
print(f"  -> Exists? {os.path.exists(abs_actual_image_files_base_dir)} | Is Dir? {os.path.isdir(abs_actual_image_files_base_dir)}")

if os.path.exists(abs_actual_image_files_base_dir) and os.path.isdir(abs_actual_image_files_base_dir):
    print(f"\nSample contents of ACTUAL_IMAGE_FILES_BASE_DIR ('{abs_actual_image_files_base_dir}') (first 10 items):")
    try:
        sample_contents = os.listdir(abs_actual_image_files_base_dir)[:10]
        if not sample_contents:
            print("    -> Directory is empty or unreadable.")
        for item_idx, item in enumerate(sample_contents):
            item_abs_path = os.path.join(abs_actual_image_files_base_dir, item)
            item_type = "Dir" if os.path.isdir(item_abs_path) else "File" if os.path.isfile(item_abs_path) else "Other"
            print(f"    -> [{item_type}] {item}")
    except Exception as e:
        print(f"    -> Could not list directory contents: {e}")
else:
    print("\nCRITICAL WARNING: ACTUAL_IMAGE_FILES_BASE_DIR does not exist or is not a directory. Path searches will fail.")
print("--- End of Initial Path Configuration Debug ---\n")



print("Proceeding with CSV loading...")
loaded_dfs = []

# Load Calc cases
if os.path.exists(abs_calc_metadata_csv_path):
    try:
        calc_df = pd.read_csv(abs_calc_metadata_csv_path)
        calc_df[CASE_TYPE_COLUMN_NAME] = 'calc' # Add case type identifier
        loaded_dfs.append(calc_df)
        print(f"Successfully loaded and tagged {len(calc_df)} rows from {CALC_METADATA_CSV_PATH}")
    except Exception as e:
        print(f"An error occurred while loading the CALC CSV ({CALC_METADATA_CSV_PATH}): {e}")
else:
    print(f"WARNING: CALC CSV file not found at {abs_calc_metadata_csv_path}. Skipping.")

# Load Mass cases
if os.path.exists(abs_mass_metadata_csv_path):
    try:
        mass_df = pd.read_csv(abs_mass_metadata_csv_path)
        mass_df[CASE_TYPE_COLUMN_NAME] = 'mass' # Add case type identifier
        loaded_dfs.append(mass_df)
        print(f"Successfully loaded and tagged {len(mass_df)} rows from {MASS_METADATA_CSV_PATH}")
    except Exception as e:
        print(f"An error occurred while loading the MASS CSV ({MASS_METADATA_CSV_PATH}): {e}")
else:
    print(f"WARNING: MASS CSV file not found at {abs_mass_metadata_csv_path}. Skipping.")

if not loaded_dfs:
    print("ERROR: No CSV files were loaded. Cannot proceed.")
    raise FileNotFoundError("Neither Calc nor Mass CSV files could be loaded. Check paths and file existence.")

source_df = pd.concat(loaded_dfs, ignore_index=True)
print(f"Combined DataFrame created with {len(source_df)} total rows from {len(loaded_dfs)} CSV file(s).")
print(f"Columns available in combined DataFrame: {source_df.columns.tolist()}")


# Clean and filter initial dataframe
if CONCEPTUAL_ROI_COLUMN_NAME not in source_df.columns or PATHOLOGY_COLUMN_NAME not in source_df.columns:
    print(f"ERROR: Required columns for metadata ('{CONCEPTUAL_ROI_COLUMN_NAME}' or '{PATHOLOGY_COLUMN_NAME}') not in combined CSV.")
    print(f"Available columns are: {source_df.columns.tolist()}")
    raise KeyError("Missing essential columns in combined CSV.")

source_df.dropna(subset=[CONCEPTUAL_ROI_COLUMN_NAME, PATHOLOGY_COLUMN_NAME], inplace=True)
source_df = source_df[source_df[PATHOLOGY_COLUMN_NAME].isin(['MALIGNANT', 'BENIGN'])]
print(f"Rows after initial cleaning (dropna on conceptual ROI/pathology, pathology filter): {len(source_df)}")

if source_df.empty:
    raise ValueError("Combined DataFrame is empty after initial cleaning. Cannot proceed.")

def heuristic_find_image_path(row, actual_images_root_dir_abs):
    try:
        patient_id = row['patient_id']
        breast_side = row['left or right breast']
        image_view = row['image view']
        abnormality_id = str(row['abnormality id']) # Ensure it's a string for concatenation

        csv_conceptual_roi_path = str(row.get(CONCEPTUAL_ROI_COLUMN_NAME, "")).strip()

        case_type_folder_prefix = ""
        if csv_conceptual_roi_path.startswith("jpg_img/"):
            path_part = csv_conceptual_roi_path.split('/')[1] # e.g., "Calc_Training_P_00005_..." or "Mass_Test_P_00001_..."
            # Extract the part before patient_id
            # The heuristic already includes Mass_Training and Mass_Test
            if path_part.startswith("Calc_Training_"): case_type_folder_prefix = "Calc_Training"
            elif path_part.startswith("Calc_Test_"): case_type_folder_prefix = "Calc_Test"
            elif path_part.startswith("Mass_Training_"): case_type_folder_prefix = "Mass_Training"
            elif path_part.startswith("Mass_Test_"): case_type_folder_prefix = "Mass_Test"

        if not case_type_folder_prefix:
            # print(f"DEBUG (heuristic): Could not determine case_type_folder_prefix for {patient_id} from '{csv_conceptual_roi_path}'")
            return None

        # Form search pattern for directories: e.g., /path/to/jpg_img/Calc_Training_P_00005_RIGHT_CC_1-*
        dir_search_prefix = f"{case_type_folder_prefix}_{patient_id}_{breast_side}_{image_view}_{abnormality_id}"
        full_dir_search_pattern = os.path.join(actual_images_root_dir_abs, f"{dir_search_prefix}-*")

        potential_series_dirs = glob.glob(full_dir_search_pattern)

        if not potential_series_dirs:
            # print(f"DEBUG (heuristic): No series directory found for {patient_id} with pattern '{full_dir_search_pattern}'")
            return None

        roi_filename_patterns = [
            "ROI-mask-images-img_0-*.jpg", "ROI-mask-images-img_1-*.jpg", "ROI-mask-images-img_*-*.jpg"
        ]

        for series_dir_on_disk in sorted(potential_series_dirs): # Sort to get a consistent choice if multiple match
            if os.path.isdir(series_dir_on_disk):
                for pattern in roi_filename_patterns:
                    image_search_glob = os.path.join(series_dir_on_disk, pattern)
                    found_roi_files = glob.glob(image_search_glob)
                    if found_roi_files:
                        found_roi_files.sort() # Sort to get a consistent choice
                        return found_roi_files[0] # Return the first valid ROI found
        return None
    except Exception as e:
        # print(f"DEBUG (heuristic): Error for row {row.get('patient_id', 'Unknown')} ({row.get(CASE_TYPE_COLUMN_NAME, 'N/A')} case): {e}")
        return None

print("Attempting HEURISTIC search for valid ROI paths for each CSV entry...")
source_df['full_image_path'] = source_df.apply(
    lambda r: heuristic_find_image_path(r, abs_actual_image_files_base_dir), axis=1
)

# All columns from source_df (including 'case_type' and any other original metadata)
# will be carried into metadata_df for rows where an image path was found.
metadata_df = source_df.dropna(subset=['full_image_path']).copy()
found_image_count = len(metadata_df)
print(f"Found {found_image_count} actual image files (ROIs if available) after HEURISTIC search from combined data.")
print(f"Breakdown by case type (if available in metadata_df): \n{metadata_df[CASE_TYPE_COLUMN_NAME].value_counts()}")


if found_image_count == 0:
    print("CRITICAL ERROR: Still no valid image files found even after heuristic search from combined data.")
    raise FileNotFoundError("No usable image files found even with heuristic search from combined data.")

metadata_df.rename(columns={'full_image_path': 'full_roi_path'}, inplace=True)

label_encoder = LabelEncoder()
# Ensure 'pathology_encoded' is created correctly on the copied DataFrame slice
metadata_df.loc[:, 'pathology_encoded'] = label_encoder.fit_transform(metadata_df[PATHOLOGY_COLUMN_NAME])
target_names = list(label_encoder.classes_)

# X will contain the image paths, y will contain the encoded labels.
# All other metadata columns (like 'patient_id', 'case_type', etc.) remain in metadata_df
# and can be used for deeper analysis or if a multi-input model is developed later.
X = metadata_df['full_roi_path']
y = metadata_df['pathology_encoded']
print(f"Number of samples going into train_test_split: {len(X)}")

if len(X) == 0:
     raise ValueError("Dataset is empty, cannot split.")

# Stratify by y to ensure balanced splits, especially important if classes are imbalanced
# or if combining datasets leads to different proportions.
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y
)
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=0.15, random_state=RANDOM_STATE, stratify=y_train_val # Stratify this split too
)

print(f"Training samples: {len(X_train)}")
print(f"Validation samples: {len(X_val)}")
print(f"Test samples: {len(X_test)}")

# Print class distribution in each set to verify stratification
print(f"Train labels distribution: {np.bincount(y_train)}")
print(f"Validation labels distribution: {np.bincount(y_val)}")
print(f"Test labels distribution: {np.bincount(y_test)}")


def load_image(image_path_tensor, label_tensor):
    image_path_str = image_path_tensor.numpy().decode('utf-8')
    try:
        img = cv2.imread(image_path_str)
        if img is None: # Check if image loading failed
            dummy_img = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)
            error_label = np.int32(-1) # Special label to indicate a problem
            return dummy_img, error_label

        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
        return img, label_tensor.numpy().astype(np.int32)
    except Exception as e:
        dummy_img = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)
        error_label = np.int32(-1)
        return dummy_img, error_label

# Data Augmentation
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal_and_vertical"),
    tf.keras.layers.RandomRotation(0.2),
    tf.keras.layers.RandomZoom(0.1),
    tf.keras.layers.RandomBrightness(factor=0.1),
    tf.keras.layers.RandomContrast(factor=0.1)
])

def create_tf_dataset(image_paths, labels, batch_size, augment=False):
    image_paths_list = list(image_paths)
    labels_list = list(labels)

    dataset = tf.data.Dataset.from_tensor_slices((image_paths_list, labels_list))

    # Step 1: Load images
    dataset = dataset.map(lambda x, y: tf.py_function(
        load_image,
        [x, y],
        [tf.uint8, tf.int32]),
        num_parallel_calls=tf.data.AUTOTUNE)

    # Step 2: Filter failed loads
    dataset = dataset.filter(lambda img, label: label != -1)

    # Step 3: Set tensor shapes
    def set_shape(img, label):
        img.set_shape((IMG_WIDTH, IMG_HEIGHT, 3))
        label.set_shape(())
        return img, label
    dataset = dataset.map(set_shape, num_parallel_calls=tf.data.AUTOTUNE)

    # Cast to float32
    dataset = dataset.map(lambda img, label: (tf.cast(img, tf.float32), label),
                          num_parallel_calls=tf.data.AUTOTUNE)
    
    # Batch before augmentation
    dataset = dataset.batch(batch_size)

    # Step 4: Apply augmentation with keyword argument
    if augment:
        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y),  # Use keyword
                              num_parallel_calls=tf.data.AUTOTUNE)

    # Step 5: Apply preprocessing
    dataset = dataset.map(lambda x, y: (tf.keras.applications.efficientnet.preprocess_input(x), y),
                          num_parallel_calls=tf.data.AUTOTUNE)

    # Step 6: Prefetch
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
    return dataset

def visualize_augmentations(sample_image_paths, augmentation_layer, output_dir):
    print("Generating and saving data augmentation visualization...")
    num_examples = len(sample_image_paths)
    num_augmentations = 4 # How many augmented versions to show for each original
    
    plt.figure(figsize=(5 * num_augmentations, 5 * num_examples))
    
    for i, image_path in enumerate(sample_image_paths):
        # Load the original image using a simplified version of the preprocessing
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
        
        # Display the original image
        ax = plt.subplot(num_examples, num_augmentations + 1, i * (num_augmentations + 1) + 1)
        plt.imshow(img)
        plt.title(f"Original {i+1}")
        plt.axis("off")
        
        # Add batch dimension and apply augmentations
        img_tensor = tf.expand_dims(tf.convert_to_tensor(img), 0)
        for j in range(num_augmentations):
            augmented_image = augmentation_layer(img_tensor, training=True)
            ax = plt.subplot(num_examples, num_augmentations + 1, i * (num_augmentations + 1) + j + 2)
            plt.imshow(tf.squeeze(augmented_image, axis=0).numpy().astype("uint8"))
            plt.title(f"Augmented {j+1}")
            plt.axis("off")
            
    plt.tight_layout()
    # Save the figure to the specified output directory
    save_path = os.path.join(output_dir, "data_augmentation_examples.png")
    plt.savefig(save_path)
    print(f"Augmentation visualization saved to {save_path}")
    plt.show()

# --- Call the new visualization function ---
# Take a few sample images from the training set to show
num_viz_samples = 3
if len(X_train) >= num_viz_samples:
    visualize_augmentations(
        sample_image_paths=X_train.iloc[:num_viz_samples],
        augmentation_layer=data_augmentation,
        output_dir=OUTPUT_DIR
    )

print("Recreating TensorFlow datasets with updated image loading logic...")
train_dataset = create_tf_dataset(X_train, y_train, BATCH_SIZE, augment=True)
val_dataset = create_tf_dataset(X_val, y_val, BATCH_SIZE, augment=False)
test_dataset = create_tf_dataset(X_test, y_test, BATCH_SIZE, augment=False)

print("Verifying dataset integrity (this might take a moment)...")
train_batches = 0
train_samples_effective = 0
for images, labels in train_dataset:
    train_batches += 1
    train_samples_effective += labels.shape[0]
print(f"Number of batches in train_dataset: {train_batches}")
print(f"Effective number of samples in train_dataset after filtering: {train_samples_effective}")

if train_batches > 0:
    for images, labels in train_dataset.take(1):
        print("Sample batch shape from train_dataset:", images.shape, labels.shape)
else:
    print("Warning: train_dataset is empty after filtering. Check for widespread image loading issues.")

val_batches = 0
val_samples_effective = 0
for images, labels in val_dataset:
    val_batches +=1
    val_samples_effective += labels.shape[0]
print(f"Number of batches in val_dataset: {val_batches}")
print(f"Effective number of samples in val_dataset after filtering: {val_samples_effective}")


test_batches = 0
test_samples_effective = 0
for images, labels in test_dataset:
    test_batches += 1
    test_samples_effective += labels.shape[0]
print(f"Number of batches in test_dataset: {test_batches}")
print(f"Effective number of samples in test_dataset after filtering: {test_samples_effective}")


# Check if any dataset is empty, which could cause issues during training/evaluation
if train_samples_effective == 0 or val_samples_effective == 0:
    print("CRITICAL WARNING: Training or Validation dataset is empty after processing. Model training cannot proceed effectively.")
    # Depending on the severity, you might want to raise an error here
    # raise ValueError("Training or Validation dataset is empty.")


# %%
# --- 2. Model Architecture ---
print("\nPhase 2: Building the Model")
base_model = EfficientNetB4(include_top=False, weights='imagenet',
                            input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))
base_model.trainable = False # Start with base model frozen

inputs = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D(name="avg_pool")(x)
x = Dropout(0.3, name="top_dropout_1")(x)
x = Dense(256, activation='relu', name="dense_128")(x)
x = Dropout(0.3, name="top_dropout_2")(x)
x = Dense(512, activation='relu', name="dense_128")(x)
x = Dropout(0.3, name="top_dropout_2")(x)
x = Dense(128, activation='relu', name="dense_64")(x)
x = Dropout(0.2, name="top_dropout_3")(x)
outputs = Dense(1, activation='sigmoid', name="predictions")(x)
model = Model(inputs, outputs)

# %%
# --- 3. Model Compilation ---
print("\nPhase 3: Compiling the Model")
optimizer = Adam(learning_rate=LEARNING_RATE)

# MODIFIED: Adjust loss based on number of classes
if len(target_names) <= 2: # Binary classification (or single class if an error, but usually benign/malignant)
    loss = tf.keras.losses.BinaryCrossentropy()
    # For binary, ensure 'accuracy' is suitable. AUC, Precision, Recall are fine.
    metrics = ['accuracy', tf.keras.metrics.AUC(name='auc'),
               tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]
else: # Multiclass classification
    loss = tf.keras.losses.SparseCategoricalCrossentropy() # Assuming y_train, etc., are integer labels
    metrics = ['accuracy', tf.keras.metrics.AUC(name='auc')] # AUC might need multi_label=True or specific setup for multiclass
    # For multiclass, typical metrics are accuracy, sparse_categorical_accuracy.
    # Precision and Recall can be more complex (e.g., weighted, macro).
    # For simplicity, starting with accuracy and AUC.

model.compile(optimizer=optimizer, loss=loss, metrics=metrics)
model.summary()

print("Available metrics names:", model.metrics_names)

# %%
print("\nPhase 4: Training the Model (Head Only)")
# Ensure datasets are not empty before starting training
if train_samples_effective == 0 or val_samples_effective == 0:
    print("ERROR: Cannot start head training because train or validation dataset is empty.")
else:

    checkpoint_filepath_head = os.path.join(OUTPUT_DIR, 'best_model_head_only.keras')
    callbacks_head = [
        ModelCheckpoint(filepath=checkpoint_filepath_head, save_weights_only=False, monitor='val_auc', mode='max', save_best_only=True),
        EarlyStopping(monitor='val_auc', patience=PATIENCE_EARLY_STOPPING, mode='max', restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=PATIENCE_REDUCE_LR, min_lr=1e-7, mode='min')
    ]
    history_head = model.fit(
        train_dataset,
        epochs=EPOCHS,
        validation_data=val_dataset,
        callbacks=callbacks_head
    )
    print("Loading best weights from head training...")
    if os.path.exists(checkpoint_filepath_head):
        model.load_weights(checkpoint_filepath_head)
    else:
        print(f"Warning: Checkpoint file {checkpoint_filepath_head} not found. Using last model weights.")


# --- 4b. Fine-tuning Phase ---
print("\nPhase 4b: Fine-tuning (Unfreezing some base model layers)")
base_model.trainable = True

# Unfreeze layers from a certain block onwards in EfficientNetB4
# EfficientNetB4 has blocks named 'block2a_expand_conv', 'block3a_expand_conv', ..., 'block7a_expand_conv'
# We can choose to unfreeze from 'block6a' or 'block5a' onwards
# For this example, let's unfreeze from 'block5a' onwards.
# You might need to inspect base_model.summary() to choose the right layers.

# Fine-tuning strategy: Unfreeze more layers
# Set base_model.trainable = True first
# Then, selectively re-freeze earlier layers if desired
# For EfficientNet, it's common to unfreeze the top blocks.

fine_tune_at_layer_name = 'block6a_expand_conv' # Here we are just unfrezzing one
set_trainable = False
for layer in base_model.layers:
    if layer.name == fine_tune_at_layer_name:
        set_trainable = True
    if set_trainable:
        if not isinstance(layer, tf.keras.layers.BatchNormalization): # Keep BN frozen
            layer.trainable = True
        else:
            layer.trainable = False # Explicitly keep BN frozen
    else:
        layer.trainable = False


optimizer_fine_tune = Adam(learning_rate=LEARNING_RATE / 10) # Use a smaller LR
model.compile(optimizer=optimizer_fine_tune, loss=loss, metrics=metrics) # Re-compile
model.summary() # Show summary with new trainable params
if train_samples_effective == 0 or val_samples_effective == 0:
     print("ERROR: Cannot start fine-tuning because train or validation dataset is empty.")
else:

    checkpoint_filepath_finetune = os.path.join(OUTPUT_DIR, 'best_model_finetuned.keras')
    callbacks_finetune = [
        ModelCheckpoint(filepath=checkpoint_filepath_finetune, save_weights_only=False, monitor='val_auc', mode='max', save_best_only=True),
        EarlyStopping(monitor='val_auc', patience=PATIENCE_EARLY_STOPPING_FT, mode='max', restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=PATIENCE_REDUCE_LR_FT, min_lr=1e-8, mode='min')
    ]

    # Determine initial epoch for fine-tuning
    initial_fine_tune_epoch = 0
    if 'history_head' in locals() and hasattr(history_head, 'epoch') and history_head.epoch:
        initial_fine_tune_epoch = history_head.epoch[-1] + 1
    else: # If head training was skipped or history is unavailable
        initial_fine_tune_epoch = 0 # Or EPOCHS if you want to assume head training ran for all its epochs
        EPOCHS = 0 # Ensure we don't re-run head training if it was skipped

    history_fine_tune = model.fit(
        train_dataset,
        epochs=EPOCHS + FINE_TUNE_EPOCHS, # Total epochs
        initial_epoch=initial_fine_tune_epoch, # Continue from where head training left off
        validation_data=val_dataset,
        callbacks=callbacks_finetune
    )
    print("Loading best weights from fine-tuning...")
    if os.path.exists(checkpoint_filepath_finetune):
        model.load_weights(checkpoint_filepath_finetune)
    else:
        print(f"Warning: Checkpoint file {checkpoint_filepath_finetune} not found. Using last model weights from fine-tuning.")



# %%
# --- 5. Model Evaluation ---
print("\nPhase 5: Evaluating the Model on Test Set")

if test_samples_effective == 0:
    print("ERROR: Test dataset is empty. Cannot evaluate model.")
    test_accuracy = 0
    test_auc = 0
else:
    results = model.evaluate(test_dataset, verbose=1)
    if len(results) >= 5:  # Ensure there are enough metrics
        final_loss = results[0]
        final_acc = results[1]  # Accuracy
        final_auc = results[2]  # AUC
        final_precision = results[3]  # Precision
        final_recall = results[4]  # Recall
        print(f"Final Loss: {final_loss}")
        print(f"Final Accuracy: {final_acc}")
        print(f"Final AUC: {final_auc}")
        print(f"Final Precision: {final_precision}")
        print(f"Final Recall: {final_recall}")
        history_plot_filename = f"training_history_Acc{final_acc:.3f}_AUC{final_auc:.3f}.png"
    else:
        print("Error: Not enough metrics returned from model.evaluate")

    print("Number of results:", len(results))
    print("Results:", results)
    y_pred_proba = model.predict(test_dataset)

    # Extract true labels correctly, regardless of whether test_dataset was batched
    y_true_test = []
    for _, labels_batch in test_dataset.unbatch().batch(BATCH_SIZE): # Re-batch after unbatching to iterate easily
        y_true_test.extend(labels_batch.numpy())
    y_true_test = np.array(y_true_test)

    if len(target_names) <= 2: # Binary classification
        y_pred_classes = (y_pred_proba > 0.5).astype(int).flatten()
    else: # Multiclass classification
        y_pred_classes = np.argmax(y_pred_proba, axis=1)


    if len(y_true_test) == 0:
        print("Warning: No true labels extracted from the test set. Cannot generate classification report or confusion matrix.")
    elif len(y_true_test) != len(y_pred_classes):
         print(f"Warning: Mismatch in number of true labels ({len(y_true_test)}) and predicted classes ({len(y_pred_classes)}). Skipping report/matrix.")
    else:
        print("\nClassification Report (Test Set):")
        print(classification_report(y_true_test, y_pred_classes, target_names=target_names, labels=range(len(target_names))))


        cm = confusion_matrix(y_true_test, y_pred_classes, labels=range(len(target_names)))
        print("\nConfusion Matrix (Test Set):")
        print(cm)

        plt.figure(figsize=(8,8)) # Made figure a bit bigger
        ax = plt.gca()
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
        disp.plot(cmap=plt.cm.Blues, ax=ax, values_format='d')
        plt.title('Confusion Matrix (Test Set)', fontsize=18)
        
    
        cm_save_path = os.path.join(OUTPUT_DIR, "confusion_matrix.png")
        plt.savefig(cm_save_path)
        print(f"Confusion matrix saved to {cm_save_path}")
        plt.show()


# Plot Training History (combined)
# Ensure histories exist before trying to plot
acc, val_acc, loss_hist, val_loss_hist, auc, val_auc = [], [], [], [], [], []
epochs_range_head_len = 0

if 'history_head' in locals() and hasattr(history_head, 'history'):
    acc.extend(history_head.history.get('accuracy', []))
    val_acc.extend(history_head.history.get('val_accuracy', []))
    loss_hist.extend(history_head.history.get('loss', []))
    val_loss_hist.extend(history_head.history.get('val_loss', []))
    auc.extend(history_head.history.get('auc', []))
    val_auc.extend(history_head.history.get('val_auc', []))
    epochs_range_head_len = len(history_head.history.get('accuracy', []))

if 'history_fine_tune' in locals() and hasattr(history_fine_tune, 'history'):
    acc.extend(history_fine_tune.history.get('accuracy', []))
    val_acc.extend(history_fine_tune.history.get('val_accuracy', []))
    loss_hist.extend(history_fine_tune.history.get('loss', []))
    val_loss_hist.extend(history_fine_tune.history.get('val_loss', []))
    auc.extend(history_fine_tune.history.get('auc', []))
    val_auc.extend(history_fine_tune.history.get('val_auc', []))

epochs_range_total = range(len(acc))

if epochs_range_total: # Only plot if there's history
    plt.figure(figsize=(20, 8)) # Made figure wider
    
    # Plot Accuracy
    plt.subplot(1, 3, 1)
    plt.plot(epochs_range_total, acc, label='Training Accuracy')
    plt.plot(epochs_range_total, val_acc, label='Validation Accuracy')
    if epochs_range_head_len > 0 and epochs_range_head_len < len(epochs_range_total):
        plt.axvline(x=epochs_range_head_len -1 , color='gray', linestyle='--', label='Start Fine-tuning')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')

    # Plot Loss
    plt.subplot(1, 3, 2)
    plt.plot(epochs_range_total, loss_hist, label='Training Loss')
    plt.plot(epochs_range_total, val_loss_hist, label='Validation Loss')
    if epochs_range_head_len > 0 and epochs_range_head_len < len(epochs_range_total):
        plt.axvline(x=epochs_range_head_len -1, color='gray', linestyle='--', label='Start Fine-tuning')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')

    # Plot AUC
    plt.subplot(1, 3, 3)
    plt.plot(epochs_range_total, auc, label='Training AUC')
    plt.plot(epochs_range_total, val_auc, label='Validation AUC')
    if epochs_range_head_len > 0 and epochs_range_head_len < len(epochs_range_total):
        plt.axvline(x=epochs_range_head_len-1, color='gray', linestyle='--', label='Start Fine-tuning')
    plt.legend(loc='lower right')
    plt.title('Training and Validation AUC')
    plt.xlabel('Epochs')
    plt.ylabel('AUC')

    plt.tight_layout()
    

    print("Available metrics names:", model.metrics_names)
    # Use the metrics already extracted in the evaluation section
    final_acc = results[1]  # Accuracy
    final_auc = results[2]  # AUC
    history_plot_filename = f"training_history_Acc{final_acc:.3f}_AUC{final_auc:.3f}.png"
    history_save_path = os.path.join(OUTPUT_DIR, history_plot_filename)
    plt.savefig(history_save_path)
    print(f"Training history plot saved to {history_save_path}")
    
    plt.show()
else:
    print("No training history found to plot.")

print("\n--- End of Training ---")
------------------

----- stderr -----
2025-06-10 17:58:01.553827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1749574681.567444 1721780 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1749574681.571582 1721780 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1749574681.584029 1721780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749574681.584044 1721780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749574681.584046 1721780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1749574681.584049 1721780 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-06-10 17:58:01.587674: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----- stdout -----
All output will be saved to: /home/renato/Programming/CBIS-DDSM/run_EfficientNetB4_Binary_224_32_64_02_20250610_175803
--- Initial Path Configuration Debug ---
Current working directory (CWD): /home/renato/Programming/CBIS-DDSM
BASE_DATASET_PATH (relative from CWD as defined): ./k_CBIS-DDSM/
CALC_METADATA_CSV_PATH (relative from CWD as defined): ./k_CBIS-DDSM/calc_case(with_jpg_img).csv
MASS_METADATA_CSV_PATH (relative from CWD as defined): ./k_CBIS-DDSM/mass_case(with_jpg_img).csv
IMAGE_ROOT_DIR (relative from CWD as defined): ./k_CBIS-DDSM/
ACTUAL_IMAGE_FILES_BASE_DIR (relative from CWD as defined): ./k_CBIS-DDSM/jpg_img

Resolved BASE_DATASET_PATH to absolute: /home/renato/Programming/CBIS-DDSM/k_CBIS-DDSM
  -> Exists? True | Is Dir? True
Resolved CALC_METADATA_CSV_PATH to absolute: /home/renato/Programming/CBIS-DDSM/k_CBIS-DDSM/calc_case(with_jpg_img).csv
  -> Exists? True | Is File? True
Resolved MASS_METADATA_CSV_PATH to absolute: /home/renato/Programming/CBIS-DDSM/k_CBIS-DDSM/mass_case(with_jpg_img).csv
  -> Exists? True | Is File? True
Resolved IMAGE_ROOT_DIR to absolute: /home/renato/Programming/CBIS-DDSM/k_CBIS-DDSM
  -> Exists? True | Is Dir? True
Resolved ACTUAL_IMAGE_FILES_BASE_DIR (where series folders should be): /home/renato/Programming/CBIS-DDSM/k_CBIS-DDSM/jpg_img
  -> Exists? True | Is Dir? True

Sample contents of ACTUAL_IMAGE_FILES_BASE_DIR ('/home/renato/Programming/CBIS-DDSM/k_CBIS-DDSM/jpg_img') (first 10 items):
    -> [Dir] Mass_Training_P_01504_LEFT_MLO-1.3.6.1.4.1.9590.100.1.2.137290885511636491113029221733299061144-1.3.6.1.4.1.9590.100.1.2.9383151312430789908711205212663448581
    -> [Dir] Mass_Training_P_01801_RIGHT_MLO_1-1.3.6.1.4.1.9590.100.1.2.118822746313833519406844343091387503862-1.3.6.1.4.1.9590.100.1.2.126785172511001854329874113380477209655
    -> [Dir] Calc_Training_P_00520_LEFT_CC-1.3.6.1.4.1.9590.100.1.2.295532192912813229015348860302070641376-1.3.6.1.4.1.9590.100.1.2.46514168311136247934969722231165982372
    -> [Dir] Calc_Training_P_01579_RIGHT_MLO-1.3.6.1.4.1.9590.100.1.2.316006360113303456707966340231532492727-1.3.6.1.4.1.9590.100.1.2.362432849513329218711904211253071425502
    -> [Dir] Calc_Training_P_00395_RIGHT_MLO_2-1.3.6.1.4.1.9590.100.1.2.255227354012270965114972089860139934251-1.3.6.1.4.1.9590.100.1.2.287230627312706904405304879631302798754
    -> [Dir] Calc_Test_P_02498_RIGHT_MLO-1.3.6.1.4.1.9590.100.1.2.234958198411349241611436512031457473289-1.3.6.1.4.1.9590.100.1.2.25895118011399481537937532611545582815
    -> [Dir] Calc_Training_P_00467_LEFT_CC-1.3.6.1.4.1.9590.100.1.2.22031954013118933913745742512987301764-1.3.6.1.4.1.9590.100.1.2.244985281912684166022125638963297133648
    -> [Dir] Mass_Test_P_00598_LEFT_MLO-1.3.6.1.4.1.9590.100.1.2.404742099011686818523319371653379799335-1.3.6.1.4.1.9590.100.1.2.57356823611525636036904521060745035167
    -> [Dir] Mass_Test_P_01815_RIGHT_MLO-1.3.6.1.4.1.9590.100.1.2.50448187310878226319009501782506777765-1.3.6.1.4.1.9590.100.1.2.38716633512694080011766947013857405484
    -> [Dir] Mass_Training_P_01712_LEFT_MLO_1-1.3.6.1.4.1.9590.100.1.2.247491291112269994529394643460089286621-1.3.6.1.4.1.9590.100.1.2.249605650513853894705695011040821528011
--- End of Initial Path Configuration Debug ---

Proceeding with CSV loading...
Successfully loaded and tagged 1872 rows from ./k_CBIS-DDSM/calc_case(with_jpg_img).csv
Successfully loaded and tagged 1696 rows from ./k_CBIS-DDSM/mass_case(with_jpg_img).csv
Combined DataFrame created with 3568 total rows from 2 CSV file(s).
Columns available in combined DataFrame: ['patient_id', 'breast density', 'left or right breast', 'image view', 'abnormality id', 'abnormality type', 'calc type', 'calc distribution', 'assessment', 'pathology', 'subtlety', 'jpg_fullMammo_img_path', 'jpg_crop_img_path', 'jpg_ROI_img_path', 'case_type', 'breast_density', 'mass shape', 'mass margins']
Rows after initial cleaning (dropna on conceptual ROI/pathology, pathology filter): 2886
Attempting HEURISTIC search for valid ROI paths for each CSV entry...
----- stdout -----
Found 2883 actual image files (ROIs if available) after HEURISTIC search from combined data.
Breakdown by case type (if available in metadata_df): 
case_type
mass    1553
calc    1330
Name: count, dtype: int64
Number of samples going into train_test_split: 2883
Training samples: 2082
Validation samples: 368
Test samples: 433
Train labels distribution: [1032 1050]
Validation labels distribution: [182 186]
Test labels distribution: [215 218]
----- stderr -----
I0000 00:00:1749574705.951058 1721780 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3910 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
----- stdout -----
Generating and saving data augmentation visualization...
----- stdout -----
Augmentation visualization saved to ./run_EfficientNetB4_Binary_224_32_64_02_20250610_175803/data_augmentation_examples.png
----- stdout -----
Recreating TensorFlow datasets with updated image loading logic...
----- stdout -----
Verifying dataset integrity (this might take a moment)...
----- stderr -----
2025-06-10 17:58:42.470418: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
----- stdout -----
Number of batches in train_dataset: 66
Effective number of samples in train_dataset after filtering: 2082
----- stdout -----
Sample batch shape from train_dataset: (32, 224, 224, 3) (32,)
----- stderr -----
2025-06-10 17:58:43.387131: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
----- stdout -----
Number of batches in val_dataset: 12
Effective number of samples in val_dataset after filtering: 368
----- stderr -----
2025-06-10 17:58:47.559399: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
----- stdout -----
Number of batches in test_dataset: 14
Effective number of samples in test_dataset after filtering: 433

Phase 2: Building the Model
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
Cell [0;32mIn[1], line 435[0m
[1;32m    433[0m x [38;5;241m=[39m Dropout([38;5;241m0.2[39m, name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mtop_dropout_3[39m[38;5;124m"[39m)(x)
[1;32m    434[0m outputs [38;5;241m=[39m Dense([38;5;241m1[39m, activation[38;5;241m=[39m[38;5;124m'[39m[38;5;124msigmoid[39m[38;5;124m'[39m, name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mpredictions[39m[38;5;124m"[39m)(x)
[0;32m--> 435[0m model [38;5;241m=[39m [43mModel[49m[43m([49m[43minputs[49m[43m,[49m[43m [49m[43moutputs[49m[43m)[49m
[1;32m    437[0m [38;5;66;03m# %%[39;00m
[1;32m    438[0m [38;5;66;03m# --- 3. Model Compilation ---[39;00m
[1;32m    439[0m [38;5;28mprint[39m([38;5;124m"[39m[38;5;130;01m\n[39;00m[38;5;124mPhase 3: Compiling the Model[39m[38;5;124m"[39m)

File [0;32m~/Programming/CBIS-DDSM/.venv/lib/python3.10/site-packages/keras/src/utils/tracking.py:26[0m, in [0;36mno_automatic_dependency_tracking.<locals>.wrapper[0;34m(*args, **kwargs)[0m
[1;32m     23[0m [38;5;129m@wraps[39m(fn)
[1;32m     24[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mwrapper[39m([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs):
[1;32m     25[0m     [38;5;28;01mwith[39;00m DotNotTrackScope():
[0;32m---> 26[0m         [38;5;28;01mreturn[39;00m [43mfn[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m

File [0;32m~/Programming/CBIS-DDSM/.venv/lib/python3.10/site-packages/keras/src/models/functional.py:136[0m, in [0;36mFunctional.__init__[0;34m(self, inputs, outputs, name, **kwargs)[0m
[1;32m    133[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mall[39m(is_input_keras_tensor(t) [38;5;28;01mfor[39;00m t [38;5;129;01min[39;00m flat_inputs):
[1;32m    134[0m     inputs, outputs [38;5;241m=[39m clone_graph_nodes(inputs, outputs)
[0;32m--> 136[0m [43mFunction[49m[38;5;241;43m.[39;49m[38;5;21;43m__init__[39;49m[43m([49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43minputs[49m[43m,[49m[43m [49m[43moutputs[49m[43m,[49m[43m [49m[43mname[49m[38;5;241;43m=[39;49m[43mname[49m[43m)[49m
[1;32m    138[0m [38;5;28;01mif[39;00m trainable [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:
[1;32m    139[0m     [38;5;28mself[39m[38;5;241m.[39mtrainable [38;5;241m=[39m trainable

File [0;32m~/Programming/CBIS-DDSM/.venv/lib/python3.10/site-packages/keras/src/ops/function.py:77[0m, in [0;36mFunction.__init__[0;34m(self, inputs, outputs, name)[0m
[1;32m     74[0m [38;5;28;01mif[39;00m backend() [38;5;241m==[39m [38;5;124m"[39m[38;5;124mtensorflow[39m[38;5;124m"[39m:
[1;32m     75[0m     [38;5;28mself[39m[38;5;241m.[39m_self_setattr_tracking [38;5;241m=[39m _self_setattr_tracking
[0;32m---> 77[0m (nodes, nodes_by_depth, operations, operations_by_depth) [38;5;241m=[39m [43mmap_graph[49m[43m([49m
[1;32m     78[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_inputs[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_outputs[49m
[1;32m     79[0m [43m[49m[43m)[49m
[1;32m     80[0m [38;5;28mself[39m[38;5;241m.[39m_nodes [38;5;241m=[39m nodes
[1;32m     81[0m [38;5;28mself[39m[38;5;241m.[39m_nodes_by_depth [38;5;241m=[39m nodes_by_depth

File [0;32m~/Programming/CBIS-DDSM/.venv/lib/python3.10/site-packages/keras/src/ops/function.py:335[0m, in [0;36mmap_graph[0;34m(inputs, outputs)[0m
[1;32m    333[0m [38;5;28;01mfor[39;00m name [38;5;129;01min[39;00m all_names:
[1;32m    334[0m     [38;5;28;01mif[39;00m all_names[38;5;241m.[39mcount(name) [38;5;241m!=[39m [38;5;241m1[39m:
[0;32m--> 335[0m         [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(
[1;32m    336[0m             [38;5;124mf[39m[38;5;124m'[39m[38;5;124mThe name [39m[38;5;124m"[39m[38;5;132;01m{[39;00mname[38;5;132;01m}[39;00m[38;5;124m"[39m[38;5;124m is used [39m[38;5;132;01m{[39;00mall_names[38;5;241m.[39mcount(name)[38;5;132;01m}[39;00m[38;5;124m [39m[38;5;124m'[39m
[1;32m    337[0m             [38;5;124m"[39m[38;5;124mtimes in the model. All operation names should be unique.[39m[38;5;124m"[39m
[1;32m    338[0m         )
[1;32m    339[0m [38;5;28;01mreturn[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth

[0;31mValueError[0m: The name "dense_128" is used 2 times in the model. All operation names should be unique.

--------------------
Notebook: EfficientNetB4_224_32.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB4_224_64.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB4_224_128_512_256_128.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB7_224_32_512_256_128.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB7_224_64_512_256_128.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
Notebook: EfficientNetB0_224_32.ipynb
Error: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
['# %%', '# Import necessary libraries at the top', 'import os', 'import glob', 'import numpy as np']
...
['    plt.show()', 'else:', '    print("No training history found to plot.")', '', 'print("\\n--- End of Training ---")']
-------------------

--------------------
