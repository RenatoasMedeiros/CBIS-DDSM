{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† An√°lise e Treino de Modelo para Dete√ß√£o de Cancro da Mama\n",
                "\n",
                "##### Este notebook detalha o processo de treino de um modelo EfficientNetB0 para a classifica√ß√£o de imagens de mamografia do dataset CBIS-DDSM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "abdf8a80",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "import matplotlib.pyplot as plt\n",
                "import re\n",
                "from sklearn.model_selection import train_test_split\n",
                "from datetime import datetime\n",
                "\n",
                "# --- Configuration ---\n",
                "IMG_HEIGHT = 224\n",
                "IMG_WIDTH = 224\n",
                "BATCH_SIZE = 32\n",
                "RANDOM_STATE = 42\n",
                "tf.random.set_seed(RANDOM_STATE)\n",
                "np.random.seed(RANDOM_STATE)\n",
                "\n",
                "# --- Path Definitions ---\n",
                "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "MODEL_NAME = 'EfficientNetB0_Binary'\n",
                "RUN_NAME = f\"run_{MODEL_NAME}{IMG_WIDTH}{BATCH_SIZE}_{TIMESTAMP}\"\n",
                "OUTPUT_DIR = os.path.join(os.getcwd(), RUN_NAME)\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "print(f\"All output will be saved to: {OUTPUT_DIR}\")\n",
                "\n",
                "BASE_DATASET_PATH = './k_CBIS-DDSM/' \n",
                "CALC_METADATA_CSV_PATH = os.path.join(BASE_DATASET_PATH, 'calc_case(with_jpg_img).csv')\n",
                "MASS_METADATA_CSV_PATH = os.path.join(BASE_DATASET_PATH, 'mass_case(with_jpg_img).csv')\n",
                "IMAGE_ROOT_DIR = BASE_DATASET_PATH\n",
                "ACTUAL_IMAGE_FILES_BASE_DIR = os.path.join(IMAGE_ROOT_DIR, 'jpg_img')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e96f1311",
            "metadata": {},
            "outputs": [],
            "source": [
                "calc_metadata_df = pd.read_csv(CALC_METADATA_CSV_PATH)\n",
                "mass_metadata_df = pd.read_csv(MASS_METADATA_CSV_PATH)\n",
                "\n",
                "# Combine metadata\n",
                "metadata_df = pd.concat([calc_metadata_df, mass_metadata_df], ignore_index=True)\n",
                "\n",
                "# Function to build the full image path\n",
                "def get_full_image_path(row):\n",
                "    # Heuristically find the image file path based on the 'image file path' column\n",
                "    # This logic assumes the JPGs are in a subdir and we need to reconstruct the path\n",
                "    # Example from CSV: 'Calc-Training_P_00001_LEFT_CC/1.3.6.1.4.1.9590.100.1.2.144498529012431872337395914681283995876/1.3.6.1.4.1.9590.100.1.2.222384938513359747228385310860089886941/1-1.jpg'\n",
                "    # Expected actual path: './k_CBIS-DDSM/jpg_img/Calc-Training_P_00001_LEFT_CC_1-1.jpg' (example)\n",
                "    \n",
                "    # Extract the patient ID and image details from the path\n",
                "    parts = row['image file path'].split('/')\n",
                "    patient_dir = parts[0]\n",
                "    image_name = os.path.splitext(parts[-1])[0] # Get '1-1' from '1-1.jpg'\n",
                "    \n",
                "    # A more robust way to find the file if naming is inconsistent\n",
                "    # Let's search for a file that contains the key parts of the ID\n",
                "    search_prefix = f\"{patient_dir}_{image_name}\"\n",
                "    \n",
                "    # Search in the jpg_img directory\n",
                "    for fname in os.listdir(ACTUAL_IMAGE_FILES_BASE_DIR):\n",
                "        if fname.startswith(search_prefix) and fname.endswith('.jpg'):\n",
                "            return os.path.join(ACTUAL_IMAGE_FILES_BASE_DIR, fname)\n",
                "            \n",
                "    # Fallback or if not found\n",
                "    return None\n",
                "\n",
                "metadata_df['jpeg_image_path'] = metadata_df.apply(get_full_image_path, axis=1)\n",
                "\n",
                "# Filter out rows where no image was found\n",
                "metadata_df.dropna(subset=['jpeg_image_path'], inplace=True)\n",
                "\n",
                "# Map pathology to binary classes\n",
                "metadata_df['pathology'] = metadata_df['pathology'].apply(lambda x: 1 if x == 'MALIGNANT' else 0)\n",
                "\n",
                "print(f\"Found {len(metadata_df)} images with corresponding metadata.\")\n",
                "print(metadata_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìÅ Funcionamento e Estrutura do Dataset (CBIS-DDSM)\n",
                "\n",
                "O dataset utilizado, *Curated Breast Imaging Subset of DDSM (CBIS-DDSM)*, √© uma cole√ß√£o de mamografias digitais otimizada para a investiga√ß√£o em imagiologia m√©dica.\n",
                "\n",
                "-   *Carregamento de Metadados*: O processo inicia-se com o carregamento de metadados a partir de ficheiros CSV (calc_case(with_jpg_img).csv e mass_case(with_jpg_img).csv). Estes ficheiros cont√™m informa√ß√µes cruciais sobre cada caso, como a identifica√ß√£o do paciente, a patologia (Benigno ou Maligno) e, mais importante, os caminhos para as imagens JPEG correspondentes.\n",
                "-   *Estrutura de Dados*: Ap√≥s a leitura, os metadados s√£o combinados num √∫nico DataFrame do Pandas. O c√≥digo realiza uma pesquisa heur√≠stica para localizar os ficheiros de imagem (ROI - Region of Interest) correspondentes a cada entrada nos CSV, garantindo que o modelo treine sobre as √°reas de maior relev√¢ncia.\n",
                "-   *Classes do Problema*: O problema √© tratado como uma classifica√ß√£o bin√°ria, onde a coluna pathology √© o alvo (label). As classes s√£o *Benigno* (0) e *Maligno* (1)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0c76536",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data into training, validation, and test sets\n",
                "train_val_df, test_df = train_test_split(\n",
                "    metadata_df, \n",
                "    test_size=0.15, \n",
                "    random_state=RANDOM_STATE, \n",
                "    stratify=metadata_df['pathology']\n",
                ")\n",
                "\n",
                "train_df, val_df = train_test_split(\n",
                "    train_val_df, \n",
                "    test_size=0.15, # 15% of the remaining 85%\n",
                "    random_state=RANDOM_STATE, \n",
                "    stratify=train_val_df['pathology']\n",
                ")\n",
                "\n",
                "print(f\"Training set size: {len(train_df)}\")\n",
                "print(f\"Validation set size: {len(val_df)}\")\n",
                "print(f\"Test set size: {len(test_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚úÇ Divis√£o dos Dados de Treino e Teste\n",
                "\n",
                "Para garantir uma avalia√ß√£o robusta do modelo, o dataset foi dividido em tr√™s conjuntos distintos: treino, valida√ß√£o e teste.\n",
                "\n",
                "-   *M√©todo Utilizado*: A divis√£o foi realizada utilizando a fun√ß√£o train_test_split da biblioteca scikit-learn.\n",
                "-   *Propor√ß√£o e Estratifica√ß√£o*:\n",
                "    1.  Primeiro, os dados foram divididos num conjunto de treino (85%) e um conjunto de teste (15%).\n",
                "    2.  De seguida, o conjunto de treino foi novamente dividido para criar um conjunto de valida√ß√£o (correspondente a 15% do conjunto de treino original).\n",
                "    3.  A estratifica√ß√£o foi aplicada com base na coluna pathology (stratify=metadata_df['pathology']). Esta t√©cnica assegura que a propor√ß√£o de amostras de cada classe (Benigno vs. Maligno) seja mantida em todos os conjuntos, o que √© fundamental para datasets desequilibrados e para uma avalia√ß√£o fidedigna."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c1f72d4c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_and_preprocess_image(path, label):\n",
                "    image = tf.io.read_file(path)\n",
                "    image = tf.image.decode_jpeg(image, channels=3)\n",
                "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
                "    image = tf.cast(image, tf.float32) / 255.0 # Normalize\n",
                "    return image, label\n",
                "\n",
                "def create_dataset(df):\n",
                "    paths = df['jpeg_image_path'].values\n",
                "    labels = df['pathology'].values\n",
                "    \n",
                "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
                "    ds = ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    return ds\n",
                "\n",
                "train_ds = create_dataset(train_df)\n",
                "val_ds = create_dataset(val_df)\n",
                "test_ds = create_dataset(test_df)\n",
                "\n",
                "# --- Data Augmentation ---\n",
                "data_augmentation = tf.keras.Sequential([\n",
                "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
                "    tf.keras.layers.RandomRotation(0.1),\n",
                "    tf.keras.layers.RandomZoom(0.1),\n",
                "    tf.keras.layers.RandomContrast(0.1),\n",
                "], name='data_augmentation')\n",
                "\n",
                "def configure_for_performance(ds, augment=False):\n",
                "    ds = ds.cache()\n",
                "    if augment:\n",
                "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    ds = ds.batch(BATCH_SIZE)\n",
                "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
                "    return ds\n",
                "\n",
                "train_ds = configure_for_performance(train_ds, augment=True)\n",
                "val_ds = configure_for_performance(val_ds)\n",
                "test_ds = configure_for_performance(test_ds)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚ú® Data Augmentation\n",
                "\n",
                "Para aumentar a diversidade do conjunto de treino e mitigar o overfitting, foram aplicadas v√°rias t√©cnicas de data augmentation em tempo real atrav√©s de um modelo sequencial do Keras.\n",
                "\n",
                "-   *T√©cnicas Aplicadas*:\n",
                "    -   RandomFlip(\"horizontal\"): Inverte aleatoriamente as imagens na horizontal.\n",
                "    -   RandomRotation(0.1): Aplica rota√ß√µes aleat√≥rias at√© 10%.\n",
                "    -   RandomZoom(0.1): Aplica zoom aleat√≥rio at√© 10%.\n",
                "    -   RandomContrast(0.1): Ajusta o contraste da imagem de forma aleat√≥ria.\n",
                "\n",
                "Estas transforma√ß√µes s√£o aplicadas a cada imagem durante o treino, gerando novas variantes a cada √©poca e ajudando o modelo a generalizar melhor para dados n√£o vistos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0591f4b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Build Model ---\n",
                "base_model = tf.keras.applications.EfficientNetB0(\n",
                "    include_top=False, \n",
                "    weights='imagenet', \n",
                "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
                ")\n",
                "\n",
                "# Freeze the base model initially\n",
                "base_model.trainable = False\n",
                "\n",
                "inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
                "x = base_model(inputs, training=False) # Important: training=False for the base model\n",
                "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
                "x = tf.keras.layers.Dense(32, activation='relu')(x) # A dense layer for classification\n",
                "x = tf.keras.layers.Dropout(0.5)(x)\n",
                "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x) # Sigmoid for binary classification\n",
                "\n",
                "model = tf.keras.Model(inputs, outputs)\n",
                "\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
                ")\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "62e1c7f5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Initial Training (Head Only) ---\n",
                "epochs_head = 10\n",
                "history_head = model.fit(\n",
                "    train_ds,\n",
                "    epochs=epochs_head,\n",
                "    validation_data=val_ds\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ac55b854",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Fine-tuning --- \n",
                "base_model.trainable = True\n",
                "\n",
                "# Unfreeze layers from this point onwards\n",
                "fine_tune_at = 'block7a_expand_conv' \n",
                "for layer in base_model.layers:\n",
                "    if layer.name == fine_tune_at:\n",
                "        break\n",
                "    layer.trainable = False\n",
                "\n",
                "# Re-compile the model with a lower learning rate for fine-tuning\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
                ")\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### layer: unfreezing.png Descongelamento de Camadas (Unfreeze)\n",
                "\n",
                "A abordagem de transfer learning foi utilizada, aproveitando modelos pr√©-treinados na ImageNet, como a *EfficientNet*.\n",
                "\n",
                "-   *Fase Inicial (Feature Extraction)*: Inicialmente, o modelo base (ex: EfficientNetB0) √© carregado com os seus pesos pr√©-treinados e todas as suas camadas s√£o \"congeladas\" (base_model.trainable = False). Isto significa que apenas os pesos da cabe√ßa de classifica√ß√£o (as camadas Dense adicionadas no topo) s√£o atualizados durante as primeiras √©pocas de treino.\n",
                "\n",
                "-   *Fase Final (Fine-Tuning)*: Ap√≥s a fase inicial, um n√∫mero espec√≠fico de camadas do modelo base √© \"descongelado\" para um ajuste fino. No c√≥digo acima, a partir da camada block7a_expand_conv, todas as camadas subsequentes s√£o tornadas trein√°veis (layer.trainable = True). Esta t√©cnica permite que o modelo adapte as suas features de alto n√≠vel ao dataset espec√≠fico de mamografias, resultando geralmente num melhor desempenho."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6a4b138",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Continue training (fine-tuning)\n",
                "epochs_fine = 15\n",
                "total_epochs = epochs_head + epochs_fine\n",
                "\n",
                "history_fine = model.fit(\n",
                "    train_ds,\n",
                "    epochs=total_epochs,\n",
                "    initial_epoch=history_head.epoch[-1],\n",
                "    validation_data=val_ds\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb6dfa61",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Evaluate Model ---\n",
                "results = model.evaluate(test_ds)\n",
                "print(f\"Test Loss: {results[0]}\")\n",
                "print(f\"Test Accuracy: {results[1]}\")\n",
                "print(f\"Test AUC: {results[2]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä An√°lise Comparativa e Conclus√£o Final\n",
                "\n",
                "Ap√≥s a execu√ß√£o de m√∫ltiplos treinos com diferentes configura√ß√µes, foi realizada uma an√°lise para identificar o modelo mais performante."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "060d4ac3",
            "metadata": {},
            "source": [
                "### ‚úÖ An√°lise e Ranking dos Modelos\n",
                "\n",
                "A m√©trica *AUC (Area Under the ROC Curve)* √© frequentemente a mais robusta para problemas de classifica√ß√£o bin√°ria em contextos m√©dicos, pois avalia a capacidade do modelo de distinguir entre as classes, independentemente do threshold de classifica√ß√£o. Por esse motivo, foi a m√©trica principal escolhida para ordenar os resultados.\n",
                "\n",
                "A tabela abaixo foi ordenada pela m√©trica *AUC* de forma decrescente para identificar o melhor modelo.\n",
                "\n",
                "| Rank (por AUC) | Nome da Run                                               | Val. Accuracy | AUC   | F1-Score | Loss   |\n",
                "|:--------------:|:----------------------------------------------------------|:-------------:|:-----:|:--------:|:------:|\n",
                "| 1              | run_EfficientNetB0_Binary_224_32_20250612_094700         | 0.672         | 0.748 | 0.670    | 0.5753 |\n",
                "| 2              | run_EfficientNetB4_Binary_224_32_20250612_103418          | 0.649         | 0.739 | 0.670    | 0.6055 |\n",
                "| 3              | run_EfficientNetB0_224_64_Dropout_L2_20250612_044859      | 0.665         | 0.734 | 0.670    | 0.6393 |\n",
                "| 4              | run_EfficientNetB0_Binary_224_64_20250612_084632         | 0.644         | 0.731 | 0.670    | 0.5885 |\n",
                "| 5              | run_EfficientNetB0_224_64_BinaryCrossentropy_20250612_041203 | 0.663         | 0.730 | 0.670    | 0.5902 |\n",
                "| 6              | run_EfficientNetB0_Binary_224_128_512_256_128_20250612_091519 | 0.644         | 0.729 | 0.670    | 0.6010 |\n",
                "| 7              | run_EfficientNetB4_Binary_224_32_64_02_20250612_101235     | 0.642         | 0.725 | 0.670    | 0.6014 |\n",
                "| 8 (empate)     | run_EfficientNetB0_224_256_BinaryCrossentropy_20250612_075937 | 0.651         | 0.719 | 0.670    | 0.6091 |\n",
                "| 8 (empate)     | run_EfficientNetB4_Binary_224_64_20250612_110549          | 0.651         | 0.719 | 0.670    | 0.6211 |\n",
                "| 10             | run_EfficientNetB0_224_256_Dropout_L2_20250612_060802      | 0.637         | 0.718 | 0.670    | 0.7141 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üí° Justifica√ß√£o dos Resultados\n",
                "\n",
                "O melhor modelo (*run_EfficientNetB0_Binary_224_32_20250612_094700*) atingiu a maior pontua√ß√£o de *AUC (0.748)* e a menor *perda de valida√ß√£o/Loss (0.5753)*, indicando uma melhor capacidade de generaliza√ß√£o.\n",
                "\n",
                "* *Impacto da Arquitetura do Modelo*:\n",
                "    * *EfficientNetB0 vs. B4*: Embora o modelo EfficientNetB4 tenha alcan√ßado um bom AUC (0.739), a vers√£o B0, mais leve, demonstrou ser mais eficaz. Modelos maiores como o B4, apesar de mais poderosos, s√£o mais propensos a overfitting em datasets de tamanho m√©dio, mesmo com data augmentation. O B0 parece ter encontrado um balan√ßo ideal entre complexidade e capacidade de generaliza√ß√£o para este problema.\n",
                "* *Impacto do Head Classification e Regulariza√ß√£o*:\n",
                "    * O modelo vencedor utilizava um Head Classification mais simples (uma camada Dense com 32 neur√≥nios).\n",
                "    * Em contraste, o terceiro melhor modelo (*run_EfficientNetB0_224_64_Dropout_L2_20250612_044859*) incorporou regulariza√ß√£o L2 e Dropout, t√©cnicas eficazes contra overfitting. Embora o seu AUC tenha sido ligeiramente inferior (0.734), a sua perda de valida√ß√£o foi maior (0.6393), sugerindo que a regulariza√ß√£o pode ter sido demasiado agressiva, impedindo o modelo de aprender algumas features importantes.\n",
                "* *Impacto da Fun√ß√£o de Perda e Otimizador*:\n",
                "    * A an√°lise das execu√ß√µes que falharam (ou que tiveram desempenho inferior) sugere que a BinaryCrossentropy foi consistentemente mais eficaz do que a HingeLoss.\n",
                "    * Da mesma forma, embora os resultados n√£o permitam uma compara√ß√£o direta entre Adam e SGD, a performance dos modelos de topo, que provavelmente usaram Adam (o padr√£o no Keras), destaca a sua robustez para este tipo de problema."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclus√£o Final\n",
                "\n",
                "O modelo da execu√ß√£o **run_EfficientNetB0_Binary_224_32_20250612_094700** destacou-se como o mais performante, combinando a arquitetura EfficientNetB0 com uma cabe√ßa de classifica√ß√£o simples. Esta combina√ß√£o provou ser a mais equilibrada, evitando o overfitting de modelos mais complexos e a perda de informa√ß√£o que pode ocorrer com t√©cnicas de regulariza√ß√£o demasiado fortes."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
