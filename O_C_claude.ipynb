{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866940cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "MODEL_NAME = 'EfficientNetB0_ObjectDetection'\n",
    "\n",
    "BASE_DATASET_PATH = './k_CBIS-DDSM/'\n",
    "CALC_METADATA_CSV_PATH = os.path.join(BASE_DATASET_PATH, 'calc_case(with_jpg_img).csv')\n",
    "MASS_METADATA_CSV_PATH = os.path.join(BASE_DATASET_PATH, 'mass_case(with_jpg_img).csv')\n",
    "\n",
    "IMAGE_ROOT_DIR = BASE_DATASET_PATH\n",
    "ACTUAL_IMAGE_FILES_BASE_DIR = os.path.join(IMAGE_ROOT_DIR, 'jpg_img')\n",
    "\n",
    "# Annotation directory (you may need to create this or adapt to your annotation format)\n",
    "ANNOTATIONS_DIR = os.path.join(BASE_DATASET_PATH, 'annotations')\n",
    "\n",
    "# Column names\n",
    "CONCEPTUAL_ROI_COLUMN_NAME = 'jpg_ROI_img_path'\n",
    "PATHOLOGY_COLUMN_NAME = 'pathology'\n",
    "CASE_TYPE_COLUMN_NAME = 'case_type'\n",
    "\n",
    "# Model & Training Parameters\n",
    "IMG_WIDTH, IMG_HEIGHT = 416, 416  # Common size for object detection\n",
    "BATCH_SIZE = 16  # Smaller batch size for object detection\n",
    "EPOCHS = 300\n",
    "FINE_TUNE_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Object detection specific parameters\n",
    "MAX_OBJECTS = 5  # Maximum number of objects to detect per image\n",
    "NUM_CLASSES = 2  # BENIGN, MALIGNANT (excluding background)\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.4\n",
    "\n",
    "PATIENCE_EARLY_STOPPING = 20\n",
    "PATIENCE_REDUCE_LR = 8\n",
    "\n",
    "PATIENCE_EARLY_STOPPING_FT = 15\n",
    "PATIENCE_REDUCE_LR_FT = 5\n",
    "\n",
    "OUTPUT_DIR = os.path.join('./', f\"run_{MODEL_NAME}_{IMG_WIDTH}_{BATCH_SIZE}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"All output will be saved to: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "\n",
    "# Create annotations directory if it doesn't exist\n",
    "os.makedirs(ANNOTATIONS_DIR, exist_ok=True)\n",
    "\n",
    "# --- End of Configuration & Constants ---\n",
    "\n",
    "# %%\n",
    "# --- Data Loading and Path Finding ---\n",
    "print(\"--- Initial Path Configuration Debug ---\")\n",
    "print(f\"Current working directory (CWD): {os.getcwd()}\")\n",
    "print(f\"BASE_DATASET_PATH: {BASE_DATASET_PATH}\")\n",
    "print(f\"ANNOTATIONS_DIR: {ANNOTATIONS_DIR}\")\n",
    "\n",
    "# Load and combine datasets\n",
    "loaded_dfs = []\n",
    "\n",
    "# Load Calc cases\n",
    "if os.path.exists(CALC_METADATA_CSV_PATH):\n",
    "    try:\n",
    "        calc_df = pd.read_csv(CALC_METADATA_CSV_PATH)\n",
    "        calc_df[CASE_TYPE_COLUMN_NAME] = 'calc'\n",
    "        loaded_dfs.append(calc_df)\n",
    "        print(f\"Successfully loaded {len(calc_df)} calc cases\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading calc CSV: {e}\")\n",
    "\n",
    "# Load Mass cases\n",
    "if os.path.exists(MASS_METADATA_CSV_PATH):\n",
    "    try:\n",
    "        mass_df = pd.read_csv(MASS_METADATA_CSV_PATH)\n",
    "        mass_df[CASE_TYPE_COLUMN_NAME] = 'mass'\n",
    "        loaded_dfs.append(mass_df)\n",
    "        print(f\"Successfully loaded {len(mass_df)} mass cases\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading mass CSV: {e}\")\n",
    "\n",
    "if not loaded_dfs:\n",
    "    raise FileNotFoundError(\"No CSV files could be loaded\")\n",
    "\n",
    "source_df = pd.concat(loaded_dfs, ignore_index=True)\n",
    "print(f\"Combined DataFrame: {len(source_df)} total rows\")\n",
    "\n",
    "# Clean dataframe\n",
    "source_df.dropna(subset=[CONCEPTUAL_ROI_COLUMN_NAME, PATHOLOGY_COLUMN_NAME], inplace=True)\n",
    "source_df = source_df[source_df[PATHOLOGY_COLUMN_NAME].isin(['MALIGNANT', 'BENIGN'])]\n",
    "print(f\"After cleaning: {len(source_df)} rows\")\n",
    "\n",
    "# %%\n",
    "# --- Object Detection Data Preparation Functions ---\n",
    "\n",
    "def create_synthetic_bounding_boxes(roi_image_path, full_image_path):\n",
    "    \"\"\"\n",
    "    Create synthetic bounding boxes from ROI masks.\n",
    "    In a real scenario, you would have actual bounding box annotations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load ROI mask to extract bounding box coordinates\n",
    "        roi_img = cv2.imread(roi_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if roi_img is None:\n",
    "            return None\n",
    "        \n",
    "        # Find contours in the ROI mask\n",
    "        contours, _ = cv2.findContours(roi_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            return None\n",
    "        \n",
    "        # Get the largest contour (assuming it's the main abnormality)\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Normalize coordinates to [0, 1] range\n",
    "        img_h, img_w = roi_img.shape\n",
    "        x_norm = x / img_w\n",
    "        y_norm = y / img_h\n",
    "        w_norm = w / img_w\n",
    "        h_norm = h / img_h\n",
    "        \n",
    "        return {\n",
    "            'x_min': x_norm,\n",
    "            'y_min': y_norm,\n",
    "            'x_max': x_norm + w_norm,\n",
    "            'y_max': y_norm + h_norm,\n",
    "            'width': w_norm,\n",
    "            'height': h_norm\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bounding box for {roi_image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_annotation_file(annotation_path):\n",
    "    \"\"\"\n",
    "    Parse annotation file (supports PASCAL VOC XML format).\n",
    "    Adapt this function based on your annotation format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if annotation_path.endswith('.xml'):\n",
    "            # Parse PASCAL VOC XML format\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            annotations = []\n",
    "            for obj in root.findall('object'):\n",
    "                name = obj.find('name').text\n",
    "                bbox = obj.find('bndbox')\n",
    "                x_min = float(bbox.find('xmin').text)\n",
    "                y_min = float(bbox.find('ymin').text)\n",
    "                x_max = float(bbox.find('xmax').text)\n",
    "                y_max = float(bbox.find('ymax').text)\n",
    "                \n",
    "                # Get image dimensions for normalization\n",
    "                size = root.find('size')\n",
    "                img_width = float(size.find('width').text)\n",
    "                img_height = float(size.find('height').text)\n",
    "                \n",
    "                annotations.append({\n",
    "                    'class': name,\n",
    "                    'x_min': x_min / img_width,\n",
    "                    'y_min': y_min / img_height,\n",
    "                    'x_max': x_max / img_width,\n",
    "                    'y_max': y_max / img_height,\n",
    "                    'width': (x_max - x_min) / img_width,\n",
    "                    'height': (y_max - y_min) / img_height\n",
    "                })\n",
    "            return annotations\n",
    "            \n",
    "        elif annotation_path.endswith('.json'):\n",
    "            # Parse COCO JSON format\n",
    "            with open(annotation_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            # Add COCO parsing logic here if needed\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing annotation file {annotation_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def heuristic_find_image_path(row, actual_images_root_dir_abs):\n",
    "    \"\"\"Enhanced version of the original function\"\"\"\n",
    "    try:\n",
    "        patient_id = row['patient_id']\n",
    "        breast_side = row['left or right breast']\n",
    "        image_view = row['image view']\n",
    "        abnormality_id = str(row['abnormality id'])\n",
    "\n",
    "        csv_conceptual_roi_path = str(row.get(CONCEPTUAL_ROI_COLUMN_NAME, \"\")).strip()\n",
    "\n",
    "        case_type_folder_prefix = \"\"\n",
    "        if csv_conceptual_roi_path.startswith(\"jpg_img/\"):\n",
    "            path_part = csv_conceptual_roi_path.split('/')[1]\n",
    "            if path_part.startswith(\"Calc_Training_\"): case_type_folder_prefix = \"Calc_Training\"\n",
    "            elif path_part.startswith(\"Calc_Test_\"): case_type_folder_prefix = \"Calc_Test\"\n",
    "            elif path_part.startswith(\"Mass_Training_\"): case_type_folder_prefix = \"Mass_Training\"\n",
    "            elif path_part.startswith(\"Mass_Test_\"): case_type_folder_prefix = \"Mass_Test\"\n",
    "\n",
    "        if not case_type_folder_prefix:\n",
    "            return None, None\n",
    "\n",
    "        # Search for series directory\n",
    "        dir_search_prefix = f\"{case_type_folder_prefix}_{patient_id}_{breast_side}_{image_view}_{abnormality_id}\"\n",
    "        full_dir_search_pattern = os.path.join(actual_images_root_dir_abs, f\"{dir_search_prefix}-*\")\n",
    "        potential_series_dirs = glob.glob(full_dir_search_pattern)\n",
    "\n",
    "        if not potential_series_dirs:\n",
    "            return None, None\n",
    "\n",
    "        # Look for both ROI and full images\n",
    "        roi_filename_patterns = [\n",
    "            \"ROI-mask-images-img_0-*.jpg\", \n",
    "            \"ROI-mask-images-img_1-*.jpg\", \n",
    "            \"ROI-mask-images-img_*-*.jpg\"\n",
    "        ]\n",
    "        \n",
    "        full_image_patterns = [\n",
    "            \"full-mammogram-images-img_0-*.jpg\",\n",
    "            \"full-mammogram-images-img_1-*.jpg\", \n",
    "            \"full-mammogram-images-img_*-*.jpg\"\n",
    "        ]\n",
    "\n",
    "        for series_dir_on_disk in sorted(potential_series_dirs):\n",
    "            if os.path.isdir(series_dir_on_disk):\n",
    "                roi_path = None\n",
    "                full_path = None\n",
    "                \n",
    "                # Find ROI image\n",
    "                for pattern in roi_filename_patterns:\n",
    "                    roi_files = glob.glob(os.path.join(series_dir_on_disk, pattern))\n",
    "                    if roi_files:\n",
    "                        roi_path = sorted(roi_files)[0]\n",
    "                        break\n",
    "                \n",
    "                # Find full mammogram image\n",
    "                for pattern in full_image_patterns:\n",
    "                    full_files = glob.glob(os.path.join(series_dir_on_disk, pattern))\n",
    "                    if full_files:\n",
    "                        full_path = sorted(full_files)[0]\n",
    "                        break\n",
    "                \n",
    "                # If we have both ROI and full image, return them\n",
    "                if roi_path and full_path:\n",
    "                    return roi_path, full_path\n",
    "                # If we only have ROI, use it as both\n",
    "                elif roi_path:\n",
    "                    return roi_path, roi_path\n",
    "                    \n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "# %%\n",
    "# --- Enhanced Data Processing ---\n",
    "print(\"Searching for image paths...\")\n",
    "source_df[['roi_path', 'full_image_path']] = source_df.apply(\n",
    "    lambda r: pd.Series(heuristic_find_image_path(r, os.path.abspath(ACTUAL_IMAGE_FILES_BASE_DIR))), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter rows with valid image paths\n",
    "metadata_df = source_df.dropna(subset=['roi_path', 'full_image_path']).copy()\n",
    "print(f\"Found {len(metadata_df)} valid image pairs\")\n",
    "\n",
    "if len(metadata_df) == 0:\n",
    "    raise ValueError(\"No valid image pairs found\")\n",
    "\n",
    "# Create bounding box annotations\n",
    "print(\"Creating bounding box annotations...\")\n",
    "bounding_boxes = []\n",
    "valid_indices = []\n",
    "\n",
    "for idx, row in metadata_df.iterrows():\n",
    "    bbox = create_synthetic_bounding_boxes(row['roi_path'], row['full_image_path'])\n",
    "    if bbox is not None:\n",
    "        bbox['class'] = row[PATHOLOGY_COLUMN_NAME]\n",
    "        bounding_boxes.append(bbox)\n",
    "        valid_indices.append(idx)\n",
    "\n",
    "metadata_df = metadata_df.loc[valid_indices].copy()\n",
    "metadata_df['bounding_boxes'] = bounding_boxes\n",
    "\n",
    "print(f\"Created bounding boxes for {len(metadata_df)} images\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "metadata_df['class_id'] = label_encoder.fit_transform(metadata_df[PATHOLOGY_COLUMN_NAME])\n",
    "class_names = list(label_encoder.classes_)\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# %%\n",
    "# --- Object Detection Data Pipeline ---\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size):\n",
    "    \"\"\"Load and preprocess image for object detection\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        return np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)\n",
    "\n",
    "def create_target_tensor(bboxes_list, num_classes, max_objects):\n",
    "    \"\"\"\n",
    "    Create target tensor for object detection\n",
    "    Format: [x_center, y_center, width, height, confidence, class_probabilities...]\n",
    "    \"\"\"\n",
    "    target_size = max_objects * (5 + num_classes)  # 5 = x,y,w,h,conf + class_probs\n",
    "    targets = np.zeros(target_size, dtype=np.float32)\n",
    "    \n",
    "    for i, bbox in enumerate(bboxes_list[:max_objects]):\n",
    "        base_idx = i * (5 + num_classes)\n",
    "        \n",
    "        # Convert to center coordinates\n",
    "        x_center = (bbox['x_min'] + bbox['x_max']) / 2\n",
    "        y_center = (bbox['y_min'] + bbox['y_max']) / 2\n",
    "        width = bbox['width']\n",
    "        height = bbox['height']\n",
    "        \n",
    "        targets[base_idx] = x_center\n",
    "        targets[base_idx + 1] = y_center\n",
    "        targets[base_idx + 2] = width\n",
    "        targets[base_idx + 3] = height\n",
    "        targets[base_idx + 4] = 1.0  # confidence\n",
    "        \n",
    "        # One-hot encode class\n",
    "        if bbox['class'] == 'MALIGNANT':\n",
    "            targets[base_idx + 5] = 1.0  # malignant\n",
    "        else:\n",
    "            targets[base_idx + 6] = 1.0  # benign\n",
    "    \n",
    "    return targets\n",
    "\n",
    "def data_generator(df, batch_size, augment=False):\n",
    "    \"\"\"Data generator for object detection\"\"\"\n",
    "    indices = np.arange(len(df))\n",
    "    \n",
    "    while True:\n",
    "        if augment:\n",
    "            np.random.shuffle(indices)\n",
    "        \n",
    "        for start_idx in range(0, len(indices), batch_size):\n",
    "            batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "            \n",
    "            images = []\n",
    "            targets = []\n",
    "            \n",
    "            for idx in batch_indices:\n",
    "                row = df.iloc[idx]\n",
    "                \n",
    "                # Load image\n",
    "                img = load_and_preprocess_image(row['full_image_path'], (IMG_WIDTH, IMG_HEIGHT))\n",
    "                \n",
    "                # Create target tensor\n",
    "                bbox_data = [{\n",
    "                    'x_min': row['bounding_boxes']['x_min'],\n",
    "                    'y_min': row['bounding_boxes']['y_min'],\n",
    "                    'x_max': row['bounding_boxes']['x_max'],\n",
    "                    'y_max': row['bounding_boxes']['y_max'],\n",
    "                    'width': row['bounding_boxes']['width'],\n",
    "                    'height': row['bounding_boxes']['height'],\n",
    "                    'class': row[PATHOLOGY_COLUMN_NAME]\n",
    "                }]\n",
    "                \n",
    "                target = create_target_tensor(bbox_data, NUM_CLASSES, MAX_OBJECTS)\n",
    "                \n",
    "                images.append(img)\n",
    "                targets.append(target)\n",
    "            \n",
    "            yield np.array(images), np.array(targets)\n",
    "\n",
    "# %%\n",
    "# --- Train/Validation/Test Split ---\n",
    "X = metadata_df[['full_image_path', 'bounding_boxes', PATHOLOGY_COLUMN_NAME]]\n",
    "y = metadata_df['class_id']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.15, random_state=RANDOM_STATE, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "# %%\n",
    "# --- Object Detection Model Architecture ---\n",
    "\n",
    "def create_object_detection_model(input_shape, num_classes, max_objects):\n",
    "    \"\"\"\n",
    "    Create object detection model based on EfficientNet backbone\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Backbone (EfficientNet)\n",
    "    backbone = EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    backbone.trainable = False\n",
    "    \n",
    "    # Feature extraction\n",
    "    features = backbone(inputs)\n",
    "    \n",
    "    # Detection head\n",
    "    x = GlobalAveragePooling2D()(features)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer: [x_center, y_center, width, height, confidence, class_probs] * max_objects\n",
    "    output_size = max_objects * (5 + num_classes)\n",
    "    outputs = Dense(output_size, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model, backbone\n",
    "\n",
    "def custom_object_detection_loss(y_true, y_pred, num_classes=NUM_CLASSES, max_objects=MAX_OBJECTS):\n",
    "    \"\"\"\n",
    "    Custom loss function for object detection\n",
    "    Combines coordinate regression loss, confidence loss, and classification loss\n",
    "    \"\"\"\n",
    "    obj_size = 5 + num_classes\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for obj_idx in range(max_objects):\n",
    "        base_idx = obj_idx * obj_size\n",
    "        \n",
    "        # Extract predictions and ground truth for this object\n",
    "        pred_coords = y_pred[:, base_idx:base_idx+4]  # x, y, w, h\n",
    "        true_coords = y_true[:, base_idx:base_idx+4]\n",
    "        \n",
    "        pred_conf = y_pred[:, base_idx+4:base_idx+5]  # confidence\n",
    "        true_conf = y_true[:, base_idx+4:base_idx+5]\n",
    "        \n",
    "        pred_class = y_pred[:, base_idx+5:base_idx+5+num_classes]  # class probabilities\n",
    "        true_class = y_true[:, base_idx+5:base_idx+5+num_classes]\n",
    "        \n",
    "        # Coordinate loss (only for objects that exist)\n",
    "        coord_loss = tf.reduce_sum(true_conf * tf.square(pred_coords - true_coords))\n",
    "        \n",
    "        # Confidence loss\n",
    "        conf_loss = tf.reduce_sum(tf.square(pred_conf - true_conf))\n",
    "        \n",
    "        # Classification loss (only for objects that exist)\n",
    "        class_loss = tf.reduce_sum(true_conf * tf.reduce_sum(tf.square(pred_class - true_class), axis=1, keepdims=True))\n",
    "        \n",
    "        total_loss += coord_loss + conf_loss + class_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# %%\n",
    "# --- Model Creation and Compilation ---\n",
    "print(\"\\nCreating object detection model...\")\n",
    "model, backbone = create_object_detection_model((IMG_HEIGHT, IMG_WIDTH, 3), NUM_CLASSES, MAX_OBJECTS)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=custom_object_detection_loss,\n",
    "    metrics=['mse']  # Mean squared error as additional metric\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# %%\n",
    "# --- Training ---\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Create data generators\n",
    "train_gen = data_generator(X_train, BATCH_SIZE, augment=True)\n",
    "val_gen = data_generator(X_val, BATCH_SIZE, augment=False)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "train_steps = len(X_train) // BATCH_SIZE\n",
    "val_steps = len(X_val) // BATCH_SIZE\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_filepath = os.path.join(OUTPUT_DIR, 'best_object_detection_model.keras')\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath, \n",
    "        save_weights_only=False, \n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        save_best_only=True\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=PATIENCE_EARLY_STOPPING, \n",
    "        mode='min', \n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        patience=PATIENCE_REDUCE_LR, \n",
    "        min_lr=1e-7, \n",
    "        mode='min'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# %%\n",
    "# --- Fine-tuning ---\n",
    "print(\"\\nStarting fine-tuning...\")\n",
    "\n",
    "# Unfreeze backbone\n",
    "backbone.trainable = True\n",
    "\n",
    "# Freeze BatchNormalization layers\n",
    "for layer in backbone.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE/10),\n",
    "    loss=custom_object_detection_loss,\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "# Fine-tuning callbacks\n",
    "finetune_checkpoint = os.path.join(OUTPUT_DIR, 'best_finetuned_model.keras')\n",
    "finetune_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=finetune_checkpoint,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=PATIENCE_EARLY_STOPPING_FT,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=PATIENCE_REDUCE_LR_FT,\n",
    "        min_lr=1e-8,\n",
    "        mode='min'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Continue training\n",
    "initial_epoch = len(history.history['loss'])\n",
    "finetune_history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=initial_epoch + FINE_TUNE_EPOCHS,\n",
    "    initial_epoch=initial_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=finetune_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# %%\n",
    "# --- Evaluation and Visualization ---\n",
    "\n",
    "def decode_predictions(predictions, confidence_threshold=0.5, num_classes=NUM_CLASSES, max_objects=MAX_OBJECTS):\n",
    "    \"\"\"Decode model predictions into bounding boxes and classes\"\"\"\n",
    "    obj_size = 5 + num_classes\n",
    "    detections = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        boxes = []\n",
    "        for obj_idx in range(max_objects):\n",
    "            base_idx = obj_idx * obj_size\n",
    "            \n",
    "            # Extract predictions\n",
    "            x_center = pred[base_idx]\n",
    "            y_center = pred[base_idx + 1]\n",
    "            width = pred[base_idx + 2]\n",
    "            height = pred[base_idx + 3]\n",
    "            confidence = pred[base_idx + 4]\n",
    "            class_probs = pred[base_idx + 5:base_idx + 5 + num_classes]\n",
    "            \n",
    "            if confidence > confidence_threshold:\n",
    "                # Convert to corner coordinates\n",
    "                x_min = x_center - width / 2\n",
    "                y_min = y_center - height / 2\n",
    "                x_max = x_center + width / 2\n",
    "                y_max = y_center + height / 2\n",
    "                \n",
    "                class_id = np.argmax(class_probs)\n",
    "                class_confidence = class_probs[class_id]\n",
    "                \n",
    "                boxes.append({\n",
    "                    'x_min': x_min,\n",
    "                    'y_min': y_min,\n",
    "                    'x_max': x_max,\n",
    "                    'y_max': y_max,\n",
    "                    'confidence': confidence,\n",
    "                    'class_id': class_id,\n",
    "                    'class_confidence': class_confidence,\n",
    "                    'class_name': class_names[class_id]\n",
    "                })\n",
    "        detections.append(boxes)\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def visualize_detections(images, detections, ground_truth=None, save_path=None):\n",
    "    \"\"\"Visualize object detection results\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(6, len(images))):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Display image\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title(f'Image {i+1}')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Draw predicted bounding boxes\n",
    "        for detection in detections[i]:\n",
    "            x_min = detection['x_min'] * IMG_WIDTH\n",
    "            y_min = detection['y_min'] * IMG_HEIGHT\n",
    "            width = (detection['x_max'] - detection['x_min']) * IMG_WIDTH\n",
    "            height = (detection['y_max'] - detection['y_min']) * IMG_HEIGHT\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min), width, height,\n",
    "                linewidth=2, edgecolor='red', facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add label\n",
    "            label = f\"{detection['class_name']}: {detection['confidence']:.2f}\"\n",
    "            ax.text(x_min, y_min-5, label, color='red', fontsize=8, \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7))\n",
    "        \n",
    "        # Draw ground truth if available\n",
    "        if ground_truth and i < len(ground_truth):\n",
    "            gt_boxes = ground_truth[i]\n",
    "            for gt_box in gt_boxes:\n",
    "                x_min = gt_box['x_min'] * IMG_WIDTH\n",
    "                y_min = gt_box['y_min'] * IMG_HEIGHT\n",
    "                width = (gt_box['x_max'] - gt_box['x_min']) * IMG_WIDTH\n",
    "                height = (gt_box['y_max'] - gt_box['y_min']) * IMG_HEIGHT\n",
    "                \n",
    "                rect = patches.Rectangle(\n",
    "                    (x_min, y_min), width, height,\n",
    "                    linewidth=2, edgecolor='green', facecolor='none', linestyle='--'\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Detection visualization saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# %%\n",
    "# --- Test Set Evaluation ---\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "# Create test generator\n",
    "test_gen = data_generator(X_test, BATCH_SIZE, augment=False)\n",
    "test_steps = len(X_test) // BATCH_SIZE\n",
    "\n",
    "# Get test predictions\n",
    "test_images = []\n",
    "test_predictions = []\n",
    "test_ground_truth = []\n",
    "\n",
    "for i, (batch_images, batch_targets) in enumerate(test_gen):\n",
    "    if i >= test_steps:\n",
    "        break\n",
    "    \n",
    "    batch_preds = model.predict(batch_images, verbose=0)\n",
    "    \n",
    "    test_images.extend(batch_images)\n",
    "    test_predictions.extend(batch_preds)\n",
    "    \n",
    "    # Convert targets back to readable format for visualization\n",
    "    # This is simplified - you might want to implement proper target decoding\n",
    "    for target in batch_targets:\n",
    "        # Extract first object's ground truth (simplified)\n",
    "        gt_box = {\n",
    "            'x_min': target[0] - target[2]/2,\n",
    "            'y_min': target[1] - target[3]/2,\n",
    "            'x_max': target[0] + target[2]/2,\n",
    "            'y_max': target[1] + target[3]/2,\n",
    "            'class_name': class_names[1] if target[6] > target[5] else class_names[0]\n",
    "        }\n",
    "        test_ground_truth.append([gt_box] if target[4] > 0 else [])\n",
    "\n",
    "# Decode predictions\n",
    "decoded_predictions = decode_predictions(test_predictions, CONFIDENCE_THRESHOLD)\n",
    "\n",
    "# Visualize results\n",
    "viz_save_path = os.path.join(OUTPUT_DIR, \"detection_results.png\")\n",
    "visualize_detections(\n",
    "    test_images[:6], \n",
    "    decoded_predictions[:6], \n",
    "    test_ground_truth[:6],\n",
    "    save_path=viz_save_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
